

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Role of Tracking in Stationary envts</title>
    <meta name="description" content="paper summary">
    
    <meta name="author" content="Ritesh Goru">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/riteshgoru.css" rel="stylesheet" type="text/css" media="all">

    <!-- Mathjax Support -->
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!-- Le fav and touch icons - this is where you can add a little icon that will show up in the address bar next to the addrss adn in search history next to website name
    <link rel="SHORTCUT ICON" href="/assets/me.ico"/>
    -->
    <!-- atom & rss feed -->
    <link href="nil" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="nil" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">

    <!--Add function that displays last modified date: -->
    <script type="text/javascript">
      onload = function(){
          document.getElementById("lastModified").innerHTML = "Website last updated on " + document.lastModified.split(" ")[0];
      }
      </script>
  
  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">Ritesh Goru</a>
          <ul class="nav">
              <li><a href="/pages/about.html">about</a></li>
              <li><a href="/pages/publications.html">publications</a></li>
              <li><a href="/pages/research.html">research</a></li>
              <li><a href="/pages/notes.html">notes/blog</a></li>  
              <li><a href="/pages/projects.html">projects</a></li>
              <li><a href="/assets/CV.pdf">cv</a></li>
          </ul>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        

<div class="page-header">
  <h2>Role of Tracking in Stationary envts </h2>
</div>

<div class="row-fluid">
  <div class="span12">
    <p><strong>NOTE:</strong>  This post assumes you are acquainted with basics of Reinforcement Learning</p>

<h3 id="introduction">Introduction</h3>
<p>All the learning Algorithms have the same objective - to reach the optima (usually in finite amount of time). However there can be multiple optima and multiple ways in which it can be done. We can directly have an algorithm converge to an optima or track the best possible solution. Depending upon the type of setting in which we are in the performance of both might vary. The usual trend is to use the former for stationary envts and the latter for non-stationary ones, But this paper by \textbf{Richard S. Sutton} emphasises the importance of tracking in general by showing 3 stationary cases (\textit{temporally coherent}) in which tracking outperforms a converging algorithm</p>

<h3 id="setup">Setup</h3>
<p>They start of assuming that the data comes from a system with evolving states and hence, the usual IID assumption doesn’t hold. \textbf{Temporal Coherence} here refers to being similar in nearby time states. The first example which was demonstrated is Black and White world. It basically is a system with circular states <script type="math/tex">(S0,S1...S19)</script> and a value 0 or 1 assigned (not exactly random (eg. <script type="math/tex">S0-S10 \rightarrow 0</script> and <script type="math/tex">S11-S19 \rightarrow 1</script>)) to each state. The agent either observes the value or moves left or right (eg. <script type="math/tex">p(observe) = 0.5</script>, <script type="math/tex">p(left) = 0.25</script>, <script type="math/tex">p(right) = 0.25</script>). So, it’s a random walk with random observation.</p>

<h3 id="objective">Objective</h3>
<p>The objective is to predict the observed value (<script type="math/tex">z_{t}</script>) using a single scalar parameter and all the state values <script type="math/tex">x_{t} = 1</script>. The usual logistic regression loss over this yields an optima for prediction <script type="math/tex">y_t = 0.5</script> (Due to the walk and observation distn and circular states over a enough observations). They show that when tracking is done ie the update <script type="math/tex">w_{t+1} = w_{t} + \alpha\delta_{t}x_{t}; \delta_{t}=z_{t}-y_{t}</script> while execution (Not to be confused with usual training update rule), for a certain values of <script type="math/tex">\alpha</script> they get lower loss compared to the optima given by usual training method. They claim that the choice of <script type="math/tex">\alpha</script> depends on the degree of coherence in the envt (They show by changing the p(observe)), which sounds plausible.</p>

<h3 id="selfplay-example">Selfplay Example</h3>
<p>The second example is 5<script type="math/tex">\times</script>5 Go which is a bit more complex than the previous case. A linear function is used to approximate the value function over states. Both the converging agent and the tracking agent are trained using <script type="math/tex">TD(0)</script>. They trained them offline, online using selfplay resp. Also the training favors the converging agent a bit interm’s of experience, But still the tracking agent’s wins are more than converging agent’s. They also demonstrate an example in which even with increasing informativeness in input features the tracking agent learns a better strategy compared to the other one.</p>

<h3 id="meta-learning-and-tracking">Meta Learning and tracking</h3>
<p>The final example tries to answer if a proper <script type="math/tex">\alpha</script> could be learnt in first case. They use a meta-learning algorithm <strong>IDBD</strong> (Incremental delta-bar-delta) which parametrizes step-size <script type="math/tex">\alpha</script> with a new parameter <script type="math/tex">\beta</script>, <script type="math/tex">\alpha_{t}^{i} = e^{\beta_{t}^{i}}</script>. And <script type="math/tex">\beta</script> is updated using a meta-learning rate <script type="math/tex">\mu</script>. So, the update equation for the <script type="math/tex">\beta</script> is <script type="math/tex">\beta_{t+1}^{i}= \beta_{t}^{i} - \mu \frac{\partial L_{t}}{\partial \beta_{t}^{i}}</script>. The derivative is evaluated using chain rule. Over all update rule still remains of the same form as before except we have a new term <script type="math/tex">\beta</script> and it’s update rule is modified as <script type="math/tex">\beta_{t+1} = \beta_{t} + \mu \delta x_{t}h_{t}</script> where, <script type="math/tex">h_{t} = \frac{\partial w_{t}}{\partial \beta_{t}}</script> and it is updated accordingly. They show that over a series of extensive experiments the <script type="math/tex">\alpha</script> converges to a value around <script type="math/tex">4.5-5</script> which is nearer to the one at which lowest loss is obtained in the first case. They have also constructed a case of non-coherent black and white problem and solved it with and without IBDB. In this case the effect of meta-learning is negligible they conclude by saying this observation might be useful for meta-learning research (may be a route to resolve methodological problem)</p>

<h3 id="my-views">My Views</h3>
<ol>
  <li>
    <p>While this paper presents an overall nice view on tracking and it’s use in temporally coherent worlds, I however think using a simple black and white example to make the third point isn’t enough.</p>
  </li>
  <li>
    <p>Also, the given examples, both black and white and GO use only linear functions will this behaviour be same in the case of non-linear mappings? I think the substantial performance gain of using tracking over an converging solution decreases or the scenario might be even reversed incase of non-linear function spaces.</p>
  </li>
  <li>
    <p>This paper made me think into a different direction of what meta-learning might indicate ie from function optimisation and differential equations point of view. In optimisation course we were taught the general update rule for optimising a function f (in non-stochastic setting) is given by <script type="math/tex">x(k+1) = x(k)+a(k)h(x(k))</script> where <script type="math/tex">a(k)</script> is the update step size and <script type="math/tex">x(k)</script> is iterate. For a proper update step This is equivalent to finding the solution for the differential equation which is given by <script type="math/tex">\dot{x}(t) = h(x(t))</script> with a certain intial value. Now the question arises what happens in meta learning? The update step would be the same but the sequence <script type="math/tex">a(k)</script> itself has an update rule and hence follows a new differential equation. Can we make something out of that differential equation?</p>
  </li>
</ol>

<h3 id="to-do">To-Do</h3>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Format properly</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Include Images</li>
</ul>

  </div>
</div>


      </div>

      <hr>
      <span id="lastModified"></span>
    </div>

    
  </body>
</html>

